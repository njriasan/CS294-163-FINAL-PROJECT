{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from scipy.stats import gamma, norm, laplace\n",
    "from random import sample\n",
    "import numpy, gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class distribution():\n",
    "    def __init__(self, name, sampler, density):\n",
    "        self.name = name\n",
    "        self.sampler, self.conditional_density = sampler, density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard symmetric, mean-zero noise\n",
    "\n",
    "def gaussian_noise(location, epsilon):\n",
    "    return location + numpy.random.normal(loc = [0, 0], scale = 1 / epsilon )\n",
    "\n",
    "def gaussian_conditional(location, conditional, epsilon):\n",
    "    difference = location - conditional\n",
    "    return numpy.prod( norm.pdf(difference, scale = 1 / epsilon) )\n",
    "\n",
    "gaussian = distribution(\"Gaussian Noise\", gaussian_noise, gaussian_conditional)\n",
    "\n",
    "def laplacian_noise(location, epsilon):\n",
    "    return location + numpy.random.laplace(loc = [0, 0], scale = 1 / epsilon )\n",
    "\n",
    "def laplacian_conditional(location, conditional, epsilon):\n",
    "    difference = location - conditional\n",
    "    return numpy.prod( laplace.pdf(difference, scale = 1 / epsilon) )\n",
    "\n",
    "laplacian = distribution(\"Laplacian Noise\", laplacian_noise, laplacian_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-of-the-art noise for location-based differential privacy\n",
    "\n",
    "def geo_noise(location, epsilon):\n",
    "    theta, r = numpy.random.uniform(0, 2 * numpy.pi), gamma.ppf(numpy.random.uniform(0, 1), 2, scale = (1 / epsilon))\n",
    "    x, y = r * numpy.cos(theta), r * numpy.sin(theta)\n",
    "    return location + numpy.array([x, y])\n",
    "\n",
    "def geo_conditional(location, conditional, epsilon):\n",
    "    x, y = location - conditional\n",
    "    r = numpy.sqrt(x ** 2 + y ** 2)\n",
    "    return gamma.pdf(r, 2, scale = 1 / epsilon) * (0.5 / numpy.pi)\n",
    "\n",
    "geo_indistinguishable = distribution(\"Geo-Indistinguishability\", geo_noise, geo_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location-based k-Anonymity analogues\n",
    "\n",
    "def square_cloak(location, epsilon):\n",
    "    cloaked_x = round( location[0] * epsilon ) / epsilon\n",
    "    cloaked_y = round( location[1] * epsilon ) / epsilon\n",
    "    return ( cloaked_x + (0.5 / epsilon), cloaked_y + (0.5 / epsilon) )\n",
    "\n",
    "def square_conditional(location, conditional, epsilon):\n",
    "    return (1 / 25) if all(numpy.equal( square_cloak(location, epsilon), conditional )) else 0\n",
    "\n",
    "square_cloaking = distribution(\"Square Cloaking\", square_cloak, square_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_schemes = [ gaussian, laplacian, geo_indistinguishable, square_cloaking ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(location, center):\n",
    "    return numpy.sqrt( (location[0] - center[0]) ** 2 + (location[1] - center[1]) ** 2 )\n",
    "\n",
    "def transpose(nested):\n",
    "    return list(zip(* nested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class user:\n",
    "    def __init__(self, server, inertia = 1):\n",
    "        self.space = server.space\n",
    "        self.location_distr = self.centered_distribution( inertia )\n",
    "        self.location_distr = self.location_distr / numpy.sum(self.location_distr)\n",
    "        \n",
    "    def centered_distribution(self, inertia):\n",
    "        center  = self.space[ numpy.random.randint(0, len(self.space)) ]\n",
    "        initial = [ numpy.random.uniform(0, 2) / (distance(L, center) + 1) for L in self.space ]\n",
    "        initial = numpy.array(initial) ** inertia\n",
    "        return numpy.round( initial / numpy.sum( initial ), decimals = 3 )\n",
    "        \n",
    "    def sample(self, epochs):\n",
    "        index = numpy.random.choice( len(self.space), size = epochs, p = self.location_distr )\n",
    "        return [ self.space[i] for i in index ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class server:\n",
    "    def __init__(self, length = 75, count = 100, epochs = 250):\n",
    "        self.space = list( map(numpy.array, product(range(length), repeat = 2 )) )\n",
    "        self.users = [ user(self, numpy.random.uniform(1, 3) ) for i in range(count) ]\n",
    "        self.length, self.epochs = length * length, epochs\n",
    "        \n",
    "        self.samples = [ u.sample(epochs) for u in self.users ]\n",
    "        self.noisy_samples = {}\n",
    "        \n",
    "    def introduce_privacy(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "        for scheme in privacy_schemes:\n",
    "            sample_user = lambda user: [ scheme.sampler(location, self.epsilon) for location in user ]\n",
    "            heartbeats  = [ sample_user(user) for user in self.samples ]            \n",
    "            self.noisy_samples[ scheme.name ] = heartbeats\n",
    "        \n",
    "    def average_accuracy(self, scheme):\n",
    "        accuracy = 0\n",
    "        sample_size = ( sample( range(len(self.users)), 10 ), sample( range(self.epochs), 10 ) )\n",
    "        for user, epoch in product(* sample_size):\n",
    "                center, noisy_center = self.samples[user][epoch], self.noisy_samples[scheme.name][user][epoch]\n",
    "                accuracy = accuracy + self.accuracy( center, noisy_center, epoch, scheme )\n",
    "        return accuracy / 100\n",
    "                \n",
    "    def accuracy(self, center, noisy_center, epoch, scheme):\n",
    "        locations = transpose(self.samples)[epoch]\n",
    "        noisy_locations = transpose(self.noisy_samples[scheme.name])[epoch]\n",
    "        \n",
    "        original = set([ x for x in range(len(locations)) if distance( locations[x], center) < 10 ] )\n",
    "        private  = set([ x for x in range(len(noisy_locations)) if distance( noisy_locations[x], noisy_center ) < 10 ])\n",
    "        \n",
    "        return len(original.intersection( private )) / len(original.union( private ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class semi_honest(server):\n",
    "    def average_predictive_power(self, scheme):\n",
    "        results = [ self.noisy_estimates(scheme, i) for i in range(len(self.samples)) ]\n",
    "        return numpy.mean( results, axis = 0 ), scheme.name\n",
    "    \n",
    "    def noisy_estimates(self, scheme, user):\n",
    "        user_heartbeats = self.noisy_samples[scheme.name][user]\n",
    "        estimates = [ numpy.ones(( self.length, )) / self.length ]\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            estimates.append( self.update_MLE(estimates[-1], user_heartbeats[i], scheme) )\n",
    "            estimates[-2] = estimates[-2] ** 2\n",
    "            estimates[-2] = estimates[-2] / numpy.sum(estimates[-2])\n",
    "\n",
    "        estimates[-1] = estimates[-1] ** 2\n",
    "        estimates[-1] = estimates[-1] / numpy.sum(estimates[-1])\n",
    "        \n",
    "        true = self.users[user].location_distr\n",
    "        return numpy.fromiter( map( lambda x: self.bhattacharyya(x, true), estimates ), dtype = float )\n",
    "        \n",
    "    def update_MLE(self, distribution, heartbeat, scheme):\n",
    "        conditional = numpy.array([ scheme.conditional_density(x, heartbeat, self.epsilon) for x in self.space ])\n",
    "        distribution = distribution + conditional\n",
    "        return distribution\n",
    "        \n",
    "    def bhattacharyya(self, estimate, true):\n",
    "        return numpy.sum(numpy.sqrt(estimate * true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_scheme_accuracy(server, save = False):\n",
    "    exogenous  = numpy.arange(0.025, 1.025, 0.025)\n",
    "    endogenous = []\n",
    "    \n",
    "    for epsilon in exogenous:\n",
    "        server.introduce_privacy(epsilon)\n",
    "        endogenous.append( map(server.average_accuracy, privacy_schemes) )\n",
    "        gc.collect()\n",
    "        \n",
    "    endogenous = zip( transpose(endogenous), privacy_schemes )\n",
    "    for endog, scheme in endogenous:\n",
    "        plot.plot(exogenous, endog, label = scheme.name )\n",
    "\n",
    "    plot.legend()\n",
    "    plot.savefig(save) if save else plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_scheme_privacy(server, save = False):\n",
    "    exogenous  = range(server.epochs + 1)\n",
    "    endogenous = map( server.average_predictive_power, privacy_schemes )\n",
    "    \n",
    "    for accuracy, label in endogenous:\n",
    "        plot.plot(exogenous, accuracy, label = label)\n",
    "\n",
    "    plot.legend()\n",
    "    plot.savefig(save) if save else plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "USGS = semi_honest(length = 5, count = 10, epochs = 25)\n",
    "compare_scheme_accuracy(USGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS.introduce_privacy(0.02)\n",
    "compare_scheme_privacy(USGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.scatter( * zip(* USGS.users[0].space), s = USGS.users[0].location_distr * 100 )\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeats = USGS.noisy_samples[\"Geo-Indistinguishability\"][0]\n",
    "zero = numpy.zeros(( USGS.length, ))\n",
    "\n",
    "estimate = numpy.sum([ USGS.update_MLE(zero, heartbeats[i], geo_indistinguishable) for i in range(USGS.epochs)], axis = 0)\n",
    "estimate = estimate / sum(estimate)\n",
    "\n",
    "plot.scatter( * zip(* USGS.users[0].space), s = estimate * 100 )\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeats = USGS.noisy_samples[\"Square Cloaking\"][0]\n",
    "zero = numpy.zeros(( USGS.length, ))\n",
    "\n",
    "estimate = numpy.sum([ USGS.update_MLE(zero, heartbeats[i], square_cloaking) for i in range(USGS.epochs)], axis = 0)\n",
    "estimate = estimate / sum(estimate)\n",
    "\n",
    "plot.scatter( * zip(* USGS.users[0].space), s = estimate * 100 )\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
